<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="index_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="index_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="index_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="index_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="index_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="index_files/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">




</div>

<div id="TOC">
<ul>
<li><a href="#intro-to-rtweet">Intro to rtweet</a><ul>
<li><a href="#twitter-data">Twitter data</a></li>
<li><a href="#installing-rtweet">Installing rtweet</a></li>
<li><a href="#authorizing-access-to-twitters-apis">Authorizing access to Twitter’s APIs</a></li>
<li><a href="#package-documentation">Package documentation</a></li>
<li><a href="#searching-for-tweets">Searching for tweets</a><ul>
<li><a href="#tweets-data">Tweets data</a></li>
</ul></li>
<li><a href="#analyzing-text">Analyzing text</a></li>
<li><a href="#tracking-topic-salience">Tracking topic salience</a></li>
<li><a href="#get-sentiment-analysis">Get sentiment analysis</a></li>
<li><a href="#aggregating-features-of-twitter-statuses-using-dplyr">Aggregating features of Twitter statuses using dplyr</a></li>
</ul></li>
</ul>
</div>

<div id="intro-to-rtweet" class="section level1">
<h1>Intro to rtweet</h1>
<div id="twitter-data" class="section level2">
<h2>Twitter data</h2>
<p>Twitter data was already trendy, but the unpresidented 2016 U.S. election has elevated it to a fever pitch. One of the biggest drivers of the trend is the widespread availability of Twitter data. Twitter makes much of its user-generated data freely available to the public via Application Program Interfaces (APIs). APIs refer to sets of protocols and procedures for interacting with sites. Twitter maintains several APIs. The two most condusive to data collection are the REST API and the stream API, both of which I describe below.</p>
<p>Twitter’s REST API provides a set of protocols for exploring and interacting with Twitter data related to user statuses (tweets), user profiles and timelines, and user network connections. The data are restful in that they have been archived by Twitter. Navigating these resting endpoints can, at times, be resource intensive, but it also makes it possible to perform highly complex and specific queries.</p>
<p>Twitter data not yet archived and accessible via the REST API can be accessed using Twitter’s stream API. As its name suggests, the stream API provides users with a live stream of Twitter data. Because the data are streamed, or pushed, to the user, the stream API reduces overhead associated with performing queries on archived data sources. This makes it possible to collect large amounts of data very quickly and with relatively little strain on computational resources. The downside to the stream API is that it is limited to prospective (tracking, monitoring, etc.) but not retrospective (surveying, searching, etc.) queries.</p>
</div>
<div id="installing-rtweet" class="section level2">
<h2>Installing rtweet</h2>
<p>Install from CRAN using <code>install.packages</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## install from CRAN
<span class="kw">install.packages</span>(<span class="st">&quot;rtweet&quot;</span>)</code></pre></div>
<p>Alternatively, install the most recent [development] version from Github using <code>install_github</code> (from the devtools package).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## install from Github (dev version)
<span class="cf">if</span> (<span class="op">!</span><span class="st">&quot;devtools&quot;</span> <span class="op">%in%</span><span class="st"> </span><span class="kw">installed.packages</span>()) {
    <span class="kw">install.packages</span>(<span class="st">&quot;devtools&quot;</span>)
}
devtools<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;mkearney/rtweet&quot;</span>, <span class="dt">build_vignettes =</span> <span class="ot">TRUE</span>)</code></pre></div>
</div>
<div id="authorizing-access-to-twitters-apis" class="section level2">
<h2>Authorizing access to Twitter’s APIs</h2>
<p>I’ve tried to make the API token [oauth] process as painless as possible. That’s why I’ve included the “auth” vignette, which ships with the package and contains step-by-step instructions on how to create and manage your Twitter API token. The vignette also includes instructions for saving a token as an environment variable, which automates the token-loading process for all future sessions (at least, for the machine you’re using). View the <a href="https://mkearney.github.io/rtweet/articles/auth.html">authorization vignette online</a> or enter the following code into your R console to load the vignette locally:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Open Twitter token vignette in web browser.
<span class="kw">vignette</span>(<span class="dt">topic =</span> <span class="st">&quot;auth&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;rtweet&quot;</span>)</code></pre></div>
</div>
<div id="package-documentation" class="section level2">
<h2>Package documentation</h2>
<p>In addition to the API authorization vignette, rtweet also includes a <a href="https://mkearney.github.io/rtweet/articles/intro.html">brief package overview vignette</a> as well as a <a href="https://mkearney.github.io/rtweet/articles/stream.html">vignette demonstrating how to access Twitter’s stream API</a>. To open the vignettes locally, use the code below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## overview of rtweet package
<span class="kw">vignette</span>(<span class="dt">topic =</span> <span class="st">&quot;intro&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;rtweet&quot;</span>)

## accessing Twitter&#39;s stream API
<span class="kw">vignette</span>(<span class="dt">topic =</span> <span class="st">&quot;stream&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;rtweet&quot;</span>)</code></pre></div>
<p>And thanks to <a href="https://github.com/hadley/pkgdown">pkgdown</a>, rtweet now has a dedicated <a href="https://mkearney.github.io/rtweet">package documentation website</a>. *Btw, while I’m on the subject of package documentation/maintenance, I’d also like to point out <a href="https://github.com/mkearney/rtweet">rtweet’s Github page</a>. Contributions are welcome and if you run into any bugs or other issues, users are encouraged to <a href="https://github.com/mkearney/rtweet/issues">create an Github issue</a>.</p>
</div>
<div id="searching-for-tweets" class="section level2">
<h2>Searching for tweets</h2>
<p>Searching for tweets is easy. For example, we could search for all [publically] available statuses from the past 7-10 days that use the hashtags <code>#ica17</code> or <code>#ica2017</code>. In the code below I’ve specified 18,000 statuses (tweets), which is the maximum number a user may request every 15 minutes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## load rtweet
<span class="kw">library</span>(rtweet)

## search for tweets containing ICA17 or ICA2017 (not case sensitive)
ica17 &lt;-<span class="st"> </span><span class="kw">search_tweets</span>(
    <span class="st">&quot;#ica17 OR #ica2017&quot;</span>, <span class="dt">n =</span> <span class="dv">18000</span>, <span class="dt">include_rts =</span> <span class="ot">FALSE</span>
)</code></pre></div>
<p>If there were more than 18,000 statuses that (a) fit the search query and (b) exist in the last 7-10 days (the limit put in place by Twitter), then users can continue where they left off by using the <code>max_id</code> parameter. Since Twitter statuses are returned in order from newest to oldest, the <code>max_id</code> value should just be the last status ID returned by the previous search.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## select last (oldest) status ID from previous search
last_status_id &lt;-<span class="st">  </span>ica17<span class="op">$</span>status_id[<span class="kw">nrow</span>(ica17)]

## pass last_status_id to max_id and run search again.
ica17_contd &lt;-<span class="st"> </span><span class="kw">search_tweets</span>(
    <span class="st">&quot;#ica17 OR #ica2017&quot;</span>, <span class="dt">n =</span> <span class="dv">18000</span>, <span class="dt">include_rts =</span> <span class="ot">FALSE</span>,
    <span class="dt">max_id =</span> last_status_id
)</code></pre></div>
<div id="tweets-data" class="section level3">
<h3>Tweets data</h3>
<p>Data returned by <code>search_tweets</code> is quite extensive. One recently added feature makes navigating the data a bit easier. As of version 0.4.3, <em>rtweet</em> returns <code>tibble</code> data frames (assuming the user has installed the <em>tibble</em> package, which is a dependency for nearly all packages in the tidyverse). Tibbles are especially nice when working with larger data sets because accidental printing in R has been known to take years off of one’s life (needs citation).</p>
<div id="ts_filter-and-ts_plot" class="section level4">
<h4>ts_filter and ts_plot</h4>
<p>Included in the rtweet package are a few convenenience functions, which have been designed to assist in the analysis of Twitter data. One of these convenient functions is <code>ts_plot</code>, which is a plot-based wrapper around <code>ts_filter</code>. The <code>ts_plot</code> and <code>ts_filter</code> functions aggregate the frequency of tweets over specified intervals of time. Hence, the “ts” (time series) naming convention. In addition to aggregating the frequency of statuses, <code>ts_plot</code> will also plot the time series.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## aggregate freq of tweets in one-hour intervals
agg &lt;-<span class="st"> </span><span class="kw">ts_filter</span>(ica17, <span class="dt">by =</span> <span class="st">&quot;hours&quot;</span>)

## view data
agg</code></pre></div>
<pre><code>## # A tibble: 212 x 3
##                   time  freq filter
##                 &lt;dttm&gt; &lt;dbl&gt;  &lt;chr&gt;
##  1 2017-05-16 20:00:00     2       
##  2 2017-05-16 21:00:00     0       
##  3 2017-05-16 22:00:00     0       
##  4 2017-05-16 23:00:00     0       
##  5 2017-05-17 00:00:00     1       
##  6 2017-05-17 01:00:00     0       
##  7 2017-05-17 02:00:00     0       
##  8 2017-05-17 03:00:00     0       
##  9 2017-05-17 04:00:00     0       
## 10 2017-05-17 05:00:00     0       
## # ... with 202 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## plot data
<span class="kw">ts_plot</span>(agg)</code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-8-1.png" /><!-- --></p>
<p>The plot produced by <code>ts_plot</code> depends on whether the user has installed <em>ggplot2</em>, which is a suggested but not required package dependency for <em>rtweet</em>. If you haven’t installed <em>ggplot2</em> then I highly recommend it. Assuming you have, then the object returned by <code>ts_plot</code> can be treated like any other ggplot object, meaning you can easily add layers and customize the plot to your liking.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## load ggplot2
<span class="kw">library</span>(ggplot2)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## plot a time series of tweets, aggregating by one-hour intervals
p1 &lt;-<span class="st"> </span><span class="kw">ts_plot</span>(ica17, <span class="st">&quot;hours&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(
        <span class="dt">x =</span> <span class="st">&quot;Date and time&quot;</span>,
        <span class="dt">y =</span> <span class="st">&quot;Frequency of tweets&quot;</span>,
        <span class="dt">title =</span> <span class="st">&quot;Time series of #ICA17 tweets&quot;</span>,
        <span class="dt">subtitle =</span> <span class="st">&quot;Frequency of Twitter statuses calculated in one-hour intervals.&quot;</span>
    ) <span class="op">+</span>
<span class="st">    </span>## a custom ggplot2 theme I mocked up for ICA
<span class="st">    </span><span class="kw">theme_ica17</span>()

## render plot
p1</code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-10-1.png" /><!-- --></p>
<!-- <p align="center">
<img src="img/p1.png" alt="p1">
</p> -->
</div>
</div>
</div>
<div id="analyzing-text" class="section level2">
<h2>Analyzing text</h2>
<p>The second convenenience function for analysing tweets is <code>plain_tweets</code>. As you might guess, <code>plain_tweets</code> strips the text of the tweets down to plain text. Because there are already variables included in the default tweets data that contain links, hashtags, and mentions, those entities are stripped out of the text as well. What’s returned are lower case words. Below I’ve applied the function to the first few ICA17 tweets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## strip text of tweets
<span class="kw">plain_tweets</span>(ica17<span class="op">$</span>text[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>])</code></pre></div>
<pre><code>## [1] &quot;excellent posttruth preconference heres some background&quot;
## [2] &quot;panel w&quot;                                                
## [3] &quot;nato&quot;</code></pre>
<p>The <code>plain_tweets</code> function is relatively straight forward at cutting through the clutter, but it still may not prepare you for quick and easy analysis. For that, you can use the <code>tokenize</code> argument in <code>plain_tweets</code>. The tokenize argument will return a vector of plain text words for each tweet.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## tokenize by word
wrds &lt;-<span class="st"> </span><span class="kw">plain_tweets</span>(ica17<span class="op">$</span>text, <span class="dt">tokenize =</span> <span class="ot">TRUE</span>)
wrds[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]</code></pre></div>
<pre><code>## [[1]]
## [1] &quot;excellent&quot;     &quot;posttruth&quot;     &quot;preconference&quot; &quot;heres&quot;        
## [5] &quot;some&quot;          &quot;background&quot;   
## 
## [[2]]
## [1] &quot;panel&quot; &quot;w&quot;    
## 
## [[3]]
## [1] &quot;nato&quot;</code></pre>
<p>This can easily be converted into a word count [frequency] table, but it still leaves one problem. The most common words probably aren’t going to tell us a lot about our specific topic / set of tweets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## get word counts
wrds &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="kw">unlist</span>(wrds))

## view top 40 words
<span class="kw">head</span>(<span class="kw">sort</span>(wrds, <span class="dt">decreasing =</span> <span class="ot">TRUE</span>), <span class="dv">40</span>)</code></pre></div>
<pre><code>## 
##           the            to            of           and            in 
##           614           504           429           388           363 
##           for            on            at             a            is 
##           290           284           247           235           181 
##          from         media         about            as           san 
##           121           115           111           110           110 
##          with         diego            be             i          this 
##           108           105            98            92            91 
##            we            by           you           are           our 
##            90            88            85            78            76 
## preconference            my            it        social          that 
##            75            71            66            65            63 
##          data           not           see      research communication 
##            61            60            59            55            52 
##           now           but            up         great            us 
##            51            50            50            49            49</code></pre>
<p>See, these words don’t appear to be very unique to ICA 2017. Of course, we could always find a premade list of stopwords to exclude, but those may not appropriately reflect the medium (Twitter) here. With rtweet, however, it’s possible to create your own dictionary of stopwords by locating overlap between (a) a <em>particular</em> sample of tweets of interest and (b) a more <em>general</em> sample of tweets.</p>
<p>To do this, we’re going to search for each letter of the alphabet separated by the boolean <code>OR</code>. It’s a bit hacky, but it returns massive amounts of tweets about a wide range of topics. So, if we can identify the <em>unique</em> words used in our sample, we may yet accomplish our goal.</p>
<p>In the code below, I’ve excluded retweets since those add unnecessary redundancies (and, ideally, we’d want a diverse pool of tweets). It’s still not perfect, but it gives us a systematic starting point that I imagine could be developed into a more reliable method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## construct boolean-exploiting search query
all &lt;-<span class="st"> </span><span class="kw">paste</span>(letters, <span class="dt">collapse =</span> <span class="st">&quot; OR &quot;</span>)

## conduct search for 5,000 original (non-retweeted) tweets
sw &lt;-<span class="st"> </span><span class="kw">search_tweets</span>(all, <span class="dt">n =</span> <span class="dv">5000</span>, <span class="dt">include_rts =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## create freq table of all words from general pool of tweets
stopwords &lt;-<span class="st"> </span><span class="kw">plain_tweets</span>(sw<span class="op">$</span>text, <span class="dt">tokenize =</span> <span class="ot">TRUE</span>)
stopwords &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="kw">unlist</span>(stopwords))</code></pre></div>
<p>Now that we’ve identified the frequencies of words in this more general pool of tweets, we can exclude all ICA tweet words that appear more than N number of times in the general pool.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## cutoff
N &lt;-<span class="st"> </span>5L

## exclude all ica17 words that appear more than N times in stopwords
wrds &lt;-<span class="st"> </span>wrds[<span class="op">!</span><span class="kw">names</span>(wrds) <span class="op">%in%</span><span class="st"> </span><span class="kw">names</span>(stopwords[stopwords <span class="op">&gt;</span><span class="st"> </span>N])]

## check top words again
<span class="kw">head</span>(<span class="kw">sort</span>(wrds, <span class="dt">decreasing =</span> <span class="ot">TRUE</span>), <span class="dv">40</span>)</code></pre></div>
<pre><code>## 
##         diego preconference          data      research communication 
##           105            75            61            55            52 
##      politics    conference        indigo     political       excited 
##            48            42            40            37            36 
##       forward         panel       preconf    presenting          comm 
##            34            29            29            29            26 
##        online         paper       digital      populism      ballroom 
##            25            24            23            23            19 
##     discourse           ica          nato       session      altheide 
##            19            19            19            19            18 
##       between          join      populist   interesting         hills 
##            18            18            18            17            16 
##    technology          fear        friday       hashtag        papers 
##            16            15            15            15            15 
##  presentation      sapphire      schedule      scholars      students 
##            15            15            15            15            15</code></pre>
<p>That turned out well! These words look a lot more unique to the topic. We can quickly survey all of these words with a simple word cloud.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## get some good colors
cols &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rainbow</span>(<span class="dv">10</span>, <span class="dt">s =</span> .<span class="dv">5</span>, <span class="dt">v =</span> .<span class="dv">75</span>), <span class="dv">10</span>)

## plot word cloud
<span class="kw">par</span>(<span class="dt">bg =</span> <span class="st">&quot;black&quot;</span>)
<span class="kw">suppressWarnings</span>(wordcloud<span class="op">::</span><span class="kw">wordcloud</span>(
    <span class="dt">words =</span> <span class="kw">names</span>(wrds),
    <span class="dt">freq =</span> wrds,
    <span class="dt">min.freq =</span> <span class="dv">5</span>,
    <span class="dt">random.color =</span> <span class="ot">FALSE</span>,
    <span class="dt">colors =</span> cols,
    <span class="dt">family =</span> <span class="st">&quot;Roboto Condensed&quot;</span>,
    <span class="dt">scale =</span> <span class="kw">c</span>(<span class="dv">4</span>, .<span class="dv">25</span>))
)</code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-17-1.png" /><!-- --></p>
<!-- <p align="center">
<img src="img/p2.png" alt="p2">
</p> -->
</div>
<div id="tracking-topic-salience" class="section level2">
<h2>Tracking topic salience</h2>
<p>If we wanted to model the topics of tweets, we could conduct two searches for tweets over the same time period and then compare the frequencies of tweets over time using time series. That’s what I’ve done in the example below.</p>
<p>First I searched for tweets mentioning “North Korea”, since I know they conducted another missile test on Monday.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## search tweets mentioning north korea (missle test on Monday)
nk &lt;-<span class="st"> </span><span class="kw">search_tweets</span>(
    <span class="st">&quot;north korea&quot;</span>, <span class="dt">n =</span> <span class="dv">18000</span>, <span class="dt">include_rts =</span> <span class="ot">FALSE</span>
)</code></pre></div>
<p>Then I searched for tweets mentioning “CBO health care” (in any order, anywhere in the tweet), since I know the CBO was released on Wednesday.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## search for tweets about the CBO (released on Wed.)
cbo &lt;-<span class="st"> </span><span class="kw">search_tweets</span>(
    <span class="st">&quot;CBO health care&quot;</span>, <span class="dt">n =</span> <span class="dv">18000</span>, <span class="dt">include_rts =</span> <span class="ot">FALSE</span>
)</code></pre></div>
<p>And then I combined the two data sets into one big data frame.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## create query (search) variable
cbo<span class="op">$</span>query &lt;-<span class="st"> &quot;CBO health care&quot;</span>
nk<span class="op">$</span>query &lt;-<span class="st"> &quot;North Korea&quot;</span>

## row bind into single data frame
df &lt;-<span class="st"> </span><span class="kw">rbind</span>(cbo, nk)</code></pre></div>
<p>Using the <code>ts_plot</code> function, I then provide a list of <code>filter</code> words (via regular expression; the bar is like an “OR”). Use the <code>key</code> argument if you want to have nicer looking filter labels. By default <code>ts_plot</code> will create groups based on the text of the tweet and the filters provided. However, you can pass along the name of any variable in DF and the function will use that to classify groups. In the code below, I applied <code>plain_tweets</code> to the text to create a new variable, and then specified that I wanted to apply the filters to that variable by using the <code>txt</code> argument in <code>ts_plot</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## create plain tweets variable
df<span class="op">$</span>text_plain &lt;-<span class="st"> </span><span class="kw">plain_tweets</span>(df<span class="op">$</span>text)

## filter by search topic
p3 &lt;-<span class="st"> </span><span class="kw">ts_plot</span>(
    df, <span class="dt">by =</span> <span class="st">&quot;15 mins&quot;</span>,
    <span class="dt">filter =</span> <span class="kw">c</span>(<span class="st">&quot;cbo|health|care|bill|insured|deficit|budget&quot;</span>,
               <span class="st">&quot;korea|kim|jung un|missile&quot;</span>),
    <span class="dt">key =</span> <span class="kw">c</span>(<span class="st">&quot;CBO&quot;</span>, <span class="st">&quot;NKorea&quot;</span>),
    <span class="dt">txt =</span> <span class="st">&quot;text_plain&quot;</span>
)</code></pre></div>
<p>Now it’s easy to add more layers and make this plot look nice.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## add theme and more style layers
p3 &lt;-<span class="st"> </span>p3 <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">theme_ica17</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_x_datetime</span>(<span class="dt">date_labels =</span> <span class="st">&quot;%b %d %H:%m&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.title =</span> <span class="kw">element_blank</span>()) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="ot">NULL</span>, 
         <span class="dt">title =</span> <span class="st">&quot;Tracing topic salience in Twitter statuses&quot;</span>,
         <span class="dt">subtitle =</span> <span class="kw">paste</span>(<span class="st">&quot;Tweets (N = 23,467) were aggregated in 15-minute&quot;</span>,
                          <span class="st">&quot;intervals. Retweets were not included.&quot;</span>)
    )

## render plot
p3</code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-22-1.png" /><!-- --></p>
<!-- <p align="center">
<img src="img/p3.png" alt="p3">
</p> -->
</div>
<div id="get-sentiment-analysis" class="section level2">
<h2>Get sentiment analysis</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## conduct sentiment analysis
sa &lt;-<span class="st"> </span>syuzhet<span class="op">::</span><span class="kw">get_nrc_sentiment</span>(df<span class="op">$</span>text_plain)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## view output
tibble<span class="op">::</span><span class="kw">as_tibble</span>(sa)</code></pre></div>
<pre><code>## # A tibble: 23,467 x 10
##    anger anticipation disgust  fear   joy sadness surprise trust
##    &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;
##  1     1            0       0     1     0       1        0     0
##  2     0            0       0     0     0       0        0     1
##  3     0            0       0     0     0       1        1     0
##  4     0            0       0     0     0       1        1     0
##  5     0            0       0     0     0       1        1     0
##  6     0            0       0     0     0       0        0     0
##  7     0            1       0     0     0       0        0     1
##  8     0            0       0     0     0       0        0     0
##  9     0            0       0     0     0       1        1     0
## 10     0            0       1     0     0       1        0     0
## # ... with 23,457 more rows, and 2 more variables: negative &lt;dbl&gt;,
## #   positive &lt;dbl&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## bind columns
df &lt;-<span class="st"> </span><span class="kw">cbind</span>(df, sa)</code></pre></div>
</div>
<div id="aggregating-features-of-twitter-statuses-using-dplyr" class="section level2">
<h2>Aggregating features of Twitter statuses using dplyr</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## load dplyr
<span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(dplyr))

## create function for aggregating date-time vectors
round_time &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">interval =</span> <span class="dv">60</span>) {
    ## round off to lowest value
    rounded &lt;-<span class="st"> </span><span class="kw">floor</span>(<span class="kw">as.numeric</span>(x) <span class="op">/</span><span class="st"> </span>interval)
    ## center so value is interval mid-point
    rounded &lt;-<span class="st"> </span>rounded <span class="op">+</span><span class="st"> </span><span class="kw">round</span>(interval <span class="op">*</span><span class="st"> </span>.<span class="dv">5</span>, <span class="dv">0</span>)
    ## return to date-time
    <span class="kw">as.POSIXct</span>(rounded <span class="op">*</span><span class="st"> </span>interval, <span class="dt">origin =</span> <span class="st">&quot;1970-01-01&quot;</span>)
}

## use pipe (%&gt;%) operator for linear syntax
long_emotion_ts &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span>
<span class="st">    </span>## select variables (columns) of interest
<span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(created_at, query, anger<span class="op">:</span>positive) <span class="op">%&gt;%</span>
<span class="st">    </span>## convert created_at variable to desired interval 
<span class="st">    </span>## here I chose hours (60 seconds * 60 mins = 1 hour)
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">created_at =</span> <span class="kw">round_time</span>(created_at, <span class="dv">60</span> <span class="op">*</span><span class="st"> </span><span class="dv">60</span>)) <span class="op">%&gt;%</span>
<span class="st">    </span>## transform data to long form
<span class="st">    </span>tidyr<span class="op">::</span><span class="kw">gather</span>(sentiment, score, <span class="op">-</span>created_at, <span class="op">-</span>query) <span class="op">%&gt;%</span>
<span class="st">    </span>## group by time, query, and sentiment
<span class="st">    </span><span class="kw">group_by</span>(created_at, query, sentiment) <span class="op">%&gt;%</span>
<span class="st">    </span>## get mean for each grouping
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">score =</span> <span class="kw">mean</span>(score, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))

## view data
long_emotion_ts</code></pre></div>
<pre><code>## Source: local data frame [720 x 4]
## Groups: created_at, query [?]
## 
## # A tibble: 720 x 4
##             created_at           query    sentiment     score
##                 &lt;dttm&gt;           &lt;chr&gt;        &lt;chr&gt;     &lt;dbl&gt;
##  1 2017-08-06 07:00:00 CBO health care        anger 0.1428571
##  2 2017-08-06 07:00:00 CBO health care anticipation 1.2857143
##  3 2017-08-06 07:00:00 CBO health care      disgust 0.0000000
##  4 2017-08-06 07:00:00 CBO health care         fear 0.1428571
##  5 2017-08-06 07:00:00 CBO health care          joy 1.0000000
##  6 2017-08-06 07:00:00 CBO health care     negative 0.0000000
##  7 2017-08-06 07:00:00 CBO health care     positive 1.8571429
##  8 2017-08-06 07:00:00 CBO health care      sadness 0.0000000
##  9 2017-08-06 07:00:00 CBO health care     surprise 1.0000000
## 10 2017-08-06 07:00:00 CBO health care        trust 0.1428571
## # ... with 710 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## plot data
long_emotion_ts <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> created_at, <span class="dt">y =</span> score, <span class="dt">color =</span> query)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>sentiment, <span class="dt">scale =</span> <span class="st">&quot;free_y&quot;</span>, <span class="dt">nrow =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">theme_ica17</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>, 
          <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">9</span>),
          <span class="dt">legend.title =</span> <span class="kw">element_blank</span>()) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">scale_x_datetime</span>(<span class="dt">date_breaks =</span> <span class="st">&quot;18 hours&quot;</span>, <span class="dt">date_labels =</span> <span class="st">&quot;%b %d&quot;</span>)</code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-26-1.png" /><!-- --></p>
<p>And that’s it!</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
